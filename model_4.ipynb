{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# tf.config.set_visible_devices(tf.config.list_physical_devices('GPU'))\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras.layers import Input, Lambda\n",
    "# from keras.utils import np_utils\n",
    "# from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.get_visible_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define aspects of the model and create instances of both the \n",
    "# test and train batch generators and the complete model.\n",
    "\n",
    "imsize = 28\n",
    "batch_size = 32\n",
    "embedding_dim = 2 \n",
    "LR = 0.0001\n",
    "EPOCHS = 5\n",
    "alpha = 0.2 \n",
    "input_x=20\n",
    "input_y=125\n",
    "total_classes=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def get_image_count(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "\n",
    "    # Check if the loaded data is a numpy array\n",
    "    if isinstance(loaded_data, np.ndarray):\n",
    "        return loaded_data.shape[2]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "data_folder_path=\"data\"\n",
    "# Specify the directory path\n",
    "X_seiz_train=[]\n",
    "X_seiz_test=[]\n",
    "\n",
    "X_bckg_train=[]\n",
    "X_bckg_test=[]\n",
    "\n",
    "image_count=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def reset_image_arr(test=0):\n",
    "    global data_folder_path        \n",
    "    \n",
    "    \n",
    "    X_bckg_train, X_bckg_test, X_seiz_train, X_seiz_test=[],[],[],[]\n",
    "    print(\"   --reset image started at\",time.time(), test,len(X_bckg_train), len(X_bckg_test), len(X_seiz_train), len(X_seiz_test) )\n",
    "\n",
    "    if test==2:\n",
    "        seiz_folder_path_test=data_folder_path+\"/test_data/seiz\"\n",
    "        bckg_folder_path_test=data_folder_path+\"/test_data/bckg\"\n",
    "        seiz_file_names_test=os.listdir(seiz_folder_path_test)\n",
    "        bckg_file_names_test=os.listdir(bckg_folder_path_test)\n",
    "\n",
    "        while len(X_seiz_test)<image_count:\n",
    "            i=random.randint(0, len(seiz_file_names_test)-1)\n",
    "            file_p = os.path.join(seiz_folder_path_test, seiz_file_names_test[i])\n",
    "            with open(file_p, 'rb') as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "\n",
    "\n",
    "            n=loaded_data.shape[2]\n",
    "            x=min(1000,max(1,n//4)) \n",
    "            idx_arr=set()\n",
    "\n",
    "            while len(idx_arr) < x:\n",
    "                idx_arr.add(random.randint(0, n - 1))\n",
    "            for i in idx_arr:\n",
    "                X_seiz_test.append(loaded_data[:, :, i])\n",
    "\n",
    "        while len(X_bckg_test)<image_count:\n",
    "            i=random.randint(0, len(bckg_file_names_test)-1)\n",
    "            file_p = os.path.join(bckg_folder_path_test, bckg_file_names_test[i])\n",
    "            with open(file_p, 'rb') as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "\n",
    "            n=loaded_data.shape[2]\n",
    "            x=min(1000,max(1,n//4)) \n",
    "            idx_arr=set()\n",
    "\n",
    "            while len(idx_arr) < x:\n",
    "                idx_arr.add(random.randint(0, n - 1))\n",
    "            for i in idx_arr:\n",
    "                X_bckg_test.append(loaded_data[:, :, i])\n",
    "        \n",
    "    else:\n",
    "        seiz_folder_path_train=data_folder_path+\"/train_data/seiz\"\n",
    "        bckg_folder_path_train=data_folder_path+\"/train_data/bckg\"\n",
    "        seiz_folder_path_val=data_folder_path+\"/val_data/seiz\"\n",
    "        bckg_folder_path_val=data_folder_path+\"/val_data/bckg\"\n",
    "\n",
    "        seiz_file_names_train=os.listdir(seiz_folder_path_train)\n",
    "        bckg_file_names_train=os.listdir(bckg_folder_path_train)\n",
    "\n",
    "        seiz_file_names_val=os.listdir(seiz_folder_path_val)\n",
    "        bckg_file_names_val=os.listdir(bckg_folder_path_val)\n",
    "\n",
    "        while len(X_seiz_train)<image_count*0.8:\n",
    "            i=random.randint(0, len(seiz_file_names_train)-1)\n",
    "            file_p = os.path.join(seiz_folder_path_train, seiz_file_names_train[i])\n",
    "            with open(file_p, 'rb') as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "\n",
    "\n",
    "            n=loaded_data.shape[2]\n",
    "            x=min(1000,max(1,n//4)) \n",
    "            idx_arr=set()\n",
    "\n",
    "            while len(idx_arr) < x:\n",
    "                idx_arr.add(random.randint(0, n - 1))\n",
    "            for i in idx_arr:\n",
    "                X_seiz_train.append(loaded_data[:, :, i])\n",
    "        \n",
    "        while len(X_seiz_test)<image_count*0.2:\n",
    "            i=random.randint(0, len(seiz_file_names_val)-1)\n",
    "            file_p = os.path.join(seiz_folder_path_val, seiz_file_names_val[i])\n",
    "            with open(file_p, 'rb') as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "\n",
    "\n",
    "            n=loaded_data.shape[2]\n",
    "            x=min(1000,max(1,n//4)) \n",
    "            idx_arr=set()\n",
    "\n",
    "            while len(idx_arr) < x:\n",
    "                idx_arr.add(random.randint(0, n - 1))\n",
    "            for i in idx_arr:\n",
    "                X_seiz_test.append(loaded_data[:, :, i])\n",
    "\n",
    "        while len(X_bckg_train)<image_count*0.8:\n",
    "            i=random.randint(0, len(bckg_file_names_train)-1)\n",
    "            file_p = os.path.join(bckg_folder_path_train, bckg_file_names_train[i])\n",
    "            with open(file_p, 'rb') as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "\n",
    "            n=loaded_data.shape[2]\n",
    "            x=min(1000,max(1,n//4)) \n",
    "            idx_arr=set()\n",
    "\n",
    "            while len(idx_arr) < x:\n",
    "                idx_arr.add(random.randint(0, n - 1))\n",
    "            for i in idx_arr:\n",
    "                X_bckg_train.append(loaded_data[:, :, i])\n",
    "        \n",
    "        while len(X_bckg_test)<image_count*0.2:\n",
    "            i=random.randint(0, len(bckg_file_names_val)-1)\n",
    "            file_p = os.path.join(bckg_folder_path_val, bckg_file_names_val[i])\n",
    "            with open(file_p, 'rb') as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "\n",
    "            n=loaded_data.shape[2]\n",
    "            x=min(1000,max(1,n//4)) \n",
    "            idx_arr=set()\n",
    "\n",
    "            while len(idx_arr) < x:\n",
    "                idx_arr.add(random.randint(0, n - 1))\n",
    "            for i in idx_arr:\n",
    "                X_bckg_test.append(loaded_data[:, :, i])\n",
    "    print(\"   --reset image successfully at\",time.time(), test,len(X_bckg_train), len(X_bckg_test), len(X_seiz_train), len(X_seiz_test) )\n",
    "    return X_seiz_train, X_seiz_test, X_bckg_train, X_bckg_test\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seiz_train, X_seiz_test, X_bckg_train, X_bckg_test=reset_image_arr(test=2)\n",
    "print(len(X_bckg_train),len(X_seiz_train),len(X_bckg_test),len(X_seiz_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_bckg_train),len(X_seiz_train),len(X_bckg_test),len(X_seiz_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(label, test=0):\n",
    "    \"\"\"Choose an image from our training or test data with the\n",
    "    given label.\"\"\"\n",
    "    # if test:\n",
    "    #     y = y_test; X = X_test_paths\n",
    "    # else:\n",
    "    #     y = y_train; X = X_train_paths\n",
    "\n",
    "    # return np.random.rand(20, 125)\n",
    "    # print(\"Here\",label,test,len(X_bckg_train),len(X_seiz_train),len(X_bckg_test),len(X_seiz_test))\n",
    "    \n",
    "    idx=0\n",
    "    file_p=\"\"\n",
    "    img_idx=-1\n",
    "    try:\n",
    "        if label==0:\n",
    "            if test!=0:\n",
    "                idx = np.random.randint(len(X_bckg_test))\n",
    "                img=X_bckg_test[idx]\n",
    "            else:\n",
    "                idx = np.random.randint(len(X_bckg_train))\n",
    "                img=X_bckg_train[idx]\n",
    "\n",
    "        else:\n",
    "            if test!=0:\n",
    "                idx = np.random.randint(len(X_seiz_test))\n",
    "                img=X_seiz_test[idx]\n",
    "            else:\n",
    "                idx = np.random.randint(len(X_seiz_train))\n",
    "                img=X_seiz_train[idx]\n",
    "    except Exception as e:\n",
    "        print(\"Exception while getting image \",time.time(),label,test,len(X_bckg_train),len(X_seiz_train),len(X_bckg_test),len(X_seiz_test),e)\n",
    "        return \n",
    "\n",
    "    \n",
    "    return img\n",
    "    \n",
    "def get_triplet(test=0):\n",
    "    \"\"\"Choose a triplet (anchor, positive, negative) of images\n",
    "    such that anchor and positive have the same label and\n",
    "    anchor and negative have different labels.\"\"\"\n",
    "    a = np.random.randint(total_classes)\n",
    "    # while n == a:\n",
    "    #     # keep searching randomly!\n",
    "    #     n = np.random.randint(total_classes)\n",
    "    n=1-a\n",
    "    \n",
    "    a, p = get_image(a, test), get_image(a, test)\n",
    "    n = get_image(n, test)\n",
    "    return a, p, n\n",
    "\n",
    "def generate_triplets(test=0):\n",
    "    global X_seiz_train, X_seiz_test, X_bckg_train, X_bckg_test\n",
    "\n",
    "    \"\"\"Generate an un-ending stream (ie a generator) of triplets for\n",
    "    training or test.\"\"\"\n",
    "    limit=0\n",
    "    while True:\n",
    "        if limit%100==0:\n",
    "            print(\"--Calling reset_image at \",time.time())\n",
    "            X_seiz_train, X_seiz_test, X_bckg_train, X_bckg_test=reset_image_arr(test)\n",
    "\n",
    "            \n",
    "        # print(1)\n",
    "        list_a = []\n",
    "        list_p = []\n",
    "        list_n = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # print(i)\n",
    "            a, p, n = get_triplet(test)\n",
    "            list_a.append(a)\n",
    "            list_p.append(p)\n",
    "            list_n.append(n)\n",
    "            \n",
    "        A = np.array(list_a, dtype='float32')\n",
    "        P = np.array(list_p, dtype='float32')\n",
    "        N = np.array(list_n, dtype='float32')\n",
    "        # a \"dummy\" label which will come in to our identity loss\n",
    "        # function below as y_true. We'll ignore it.\n",
    "        label = np.ones(batch_size)\n",
    "        # print(\"Batch done\",limit)\n",
    "        yield [A, P, N], label\n",
    "        limit+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_data(test=0):\n",
    "    global X_seiz_train, X_seiz_test, X_bckg_train, X_bckg_test\n",
    "    \"\"\"Generate an un-ending stream (ie a generator) of triplets for\n",
    "    training or test.\"\"\"\n",
    "    limit=0\n",
    "    while True:\n",
    "        if limit%100==0:\n",
    "            print(\"--Calling reset_image at \",time.time())\n",
    "            X_seiz_train, X_seiz_test, X_bckg_train, X_bckg_test=reset_image_arr(test)\n",
    "            \n",
    "        # print(1)\n",
    "        a=[]\n",
    "        label=[]\n",
    "        for i in range(batch_size//2):\n",
    "            # print(i)\n",
    "            img_b=get_image(0,test)\n",
    "            a.append(img_b)\n",
    "            label.append(0)\n",
    "            img_s=get_image(1,test)\n",
    "            a.append(img_s)\n",
    "            label.append(1)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        A = np.array(a, dtype='float32')\n",
    "        label = np.array(label)\n",
    "\n",
    "        rng_state = np.random.get_state()\n",
    "\n",
    "        # Shuffle the first array\n",
    "        np.random.shuffle(A)\n",
    "\n",
    "        # Set the random state to the state obtained earlier\n",
    "        np.random.set_state(rng_state)\n",
    "\n",
    "        # Shuffle the second array\n",
    "        np.random.shuffle(label)\n",
    "        # print(\"Batch done\",limit)\n",
    "        yield [A], label\n",
    "        limit+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = generate_classification_data(test=0)\n",
    "next(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_image(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# def get_triplet_batch(test=False):\n",
    "#     x=(batch_size//2)*3\n",
    "#     if test:\n",
    "#         n=len(X_bckg_test)-1\n",
    "#     else:\n",
    "#         n=len(X_bckg_train)-1\n",
    "\n",
    "\n",
    "#     A=[]\n",
    "#     P=[]\n",
    "#     N=[]\n",
    "\n",
    "#     bckg = [random.randint(0, n) for _ in range(x)]\n",
    "\n",
    "#     if test:\n",
    "#         n=len(X_seiz_test)-1\n",
    "#     else:\n",
    "#         n=len(X_seiz_train)-1\n",
    "\n",
    "#     seiz = [random.randint(0, n) for _ in range(x)]\n",
    "\n",
    "#     if test:\n",
    "#         for i in range(batch_size//2):\n",
    "#             file_p_a, img_idx_a=X_bckg_test[bckg[2*i]]\n",
    "#             file_p_p, img_idx_p=X_bckg_test[bckg[2*i+1]]\n",
    "#             file_p_n, img_idx_n=X_seiz_test[seiz[i]]\n",
    "#             with open(file_p_a, 'rb') as f_a:\n",
    "#                 loaded_data_a = pickle.load(f_a)\n",
    "#             A.append(loaded_data_a[:, :, img_idx_a])\n",
    "\n",
    "#             with open(file_p_p, 'rb') as f_p:\n",
    "#                 loaded_data_p = pickle.load(f_p)\n",
    "#             P.append(loaded_data_p[:, :, img_idx_p])\n",
    "\n",
    "#             with open(file_p_n, 'rb') as f_n:\n",
    "#                 loaded_data_n = pickle.load(f_n)\n",
    "#             N.append(loaded_data_n[:, :, img_idx_n])\n",
    "\n",
    "        \n",
    "#         for i in range(batch_size//2):\n",
    "#             file_p_a, img_idx_a=X_seiz_test[seiz[batch_size//2+2*i]]\n",
    "#             file_p_p, img_idx_p=X_seiz_test[seiz[batch_size//2+2*i+1]]\n",
    "#             file_p_n, img_idx_n=X_bckg_test[bckg[batch_size+i]]\n",
    "#             with open(file_p_a, 'rb') as f_a:\n",
    "#                 loaded_data_a = pickle.load(f_a)\n",
    "#             A.append(loaded_data_a[:, :, img_idx_a])\n",
    "\n",
    "#             with open(file_p_p, 'rb') as f_p:\n",
    "#                 loaded_data_p = pickle.load(f_p)\n",
    "#             P.append(loaded_data_p[:, :, img_idx_p])\n",
    "\n",
    "#             with open(file_p_n, 'rb') as f_n:\n",
    "#                 loaded_data_n = pickle.load(f_n)\n",
    "#             N.append(loaded_data_n[:, :, img_idx_n])\n",
    "\n",
    "#     else:\n",
    "#         for i in range(batch_size//2):\n",
    "#             file_p_a, img_idx_a=X_bckg_train[bckg[2*i]]\n",
    "#             file_p_p, img_idx_p=X_bckg_train[bckg[2*i+1]]\n",
    "#             file_p_n, img_idx_n=X_seiz_train[seiz[i]]\n",
    "#             with open(file_p_a, 'rb') as f_a:\n",
    "#                 loaded_data_a = pickle.load(f_a)\n",
    "#             A.append(loaded_data_a[:, :, img_idx_a])\n",
    "\n",
    "#             with open(file_p_p, 'rb') as f_p:\n",
    "#                 loaded_data_p = pickle.load(f_p)\n",
    "#             P.append(loaded_data_p[:, :, img_idx_p])\n",
    "\n",
    "#             with open(file_p_n, 'rb') as f_n:\n",
    "#                 loaded_data_n = pickle.load(f_n)\n",
    "#             N.append(loaded_data_n[:, :, img_idx_n])\n",
    "\n",
    "        \n",
    "#         for i in range(batch_size//2):\n",
    "#             file_p_a, img_idx_a=X_seiz_train[seiz[batch_size//2+2*i]]\n",
    "#             file_p_p, img_idx_p=X_seiz_train[seiz[batch_size//2+2*i+1]]\n",
    "#             file_p_n, img_idx_n=X_bckg_train[bckg[batch_size+i]]\n",
    "#             with open(file_p_a, 'rb') as f_a:\n",
    "#                 loaded_data_a = pickle.load(f_a)\n",
    "#             A.append(loaded_data_a[:, :, img_idx_a])\n",
    "\n",
    "#             with open(file_p_p, 'rb') as f_p:\n",
    "#                 loaded_data_p = pickle.load(f_p)\n",
    "#             P.append(loaded_data_p[:, :, img_idx_p])\n",
    "\n",
    "#             with open(file_p_n, 'rb') as f_n:\n",
    "#                 loaded_data_n = pickle.load(f_n)\n",
    "#             N.append(loaded_data_n[:, :, img_idx_n])\n",
    "    \n",
    "#     A = np.array(A, dtype='float32')\n",
    "#     P = np.array(P, dtype='float32')\n",
    "#     N = np.array(N, dtype='float32')\n",
    "#     print(bckg)\n",
    "\n",
    "\n",
    "# get_triplet_batch()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=[]\n",
    "# for i in range(batch_size):\n",
    "#     xx=get_triplet()\n",
    "#     t.append(xx)\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = generate_triplets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(batch[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def triplet_loss(x, alpha = 0.2):\n",
    "    # Triplet Loss function.\n",
    "    anchor,positive,negative = x\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    "    return loss\n",
    "\n",
    "def embedding_model():\n",
    "    # Simple convolutional model \n",
    "    # used for the embedding model.\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_x, input_y, 1), name='input_layer'))  # Input layer\n",
    "    model.add(Convolution2D(32, (3, 3), activation='relu', name='convolution_1'))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu', name='convolution_2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), name='max_pooling'))\n",
    "    model.add(Dropout(0.25, name='dropout_1'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(256, activation='relu', name='dense_1'))\n",
    "    model.add(Dropout(0.5, name='dropout_2'))\n",
    "    model.add(Dense(64, name='dense_2'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def complete_model(base_model):\n",
    "    # Create the complete model with three\n",
    "    # embedding models and minimize the loss \n",
    "    # between their output embeddings\n",
    "    input_1 = Input((input_x, input_y,1), name='input_layer_A')\n",
    "    input_2 = Input((input_x, input_y,1), name='input_layer_P')\n",
    "    input_3 = Input((input_x, input_y,1), name='input_layer_N')\n",
    "        \n",
    "    A = base_model(input_1)\n",
    "    P = base_model(input_2)\n",
    "    N = base_model(input_3)\n",
    "   \n",
    "    loss = Lambda(triplet_loss)([A, P, N]) \n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=loss)\n",
    "    model.compile(loss=mean_loss, optimizer=Adam(LR))\n",
    "    return model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define aspects of the model and create instances of both the \n",
    "# test and train batch generators and the complete model.\n",
    "\n",
    "# imsize = 28\n",
    "# batch_size = 100\n",
    "# embedding_dim = 2 \n",
    "# LR = 0.0001\n",
    "# EPOCHS = 5\n",
    "# alpha = 0.2 \n",
    "\n",
    "train_generator_emd = generate_triplets()\n",
    "val_generator_emd = generate_triplets(test=1)\n",
    "# batch = next(_emd)\n",
    "\n",
    "emd_model = embedding_model()\n",
    "cmp_model = complete_model(emd_model)\n",
    "cmp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emd_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.get_visible_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the model using triplet images provided by the train batch generator.\n",
    "# # Save the trained weights.\n",
    "\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# # Define a callback to save the model weights after each epoch\n",
    "# checkpoint_callback = ModelCheckpoint(filepath='model_weights/siamese_model_3.h5', \n",
    "#                                       save_weights_only=False,\n",
    "#                                       verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "# # Fit the model with the callback\n",
    "# # with tf.device(\"/cpu:0\"):\n",
    "# history = cmp_model.fit_generator(train_generator_emd, \n",
    "#                             validation_data=val_generator_emd, \n",
    "#                             epochs=5, \n",
    "#                             verbose=1,\n",
    "#                             steps_per_epoch=1000, \n",
    "#                             validation_steps=30,\n",
    "#                             callbacks=[checkpoint_callback])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.get_visible_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Fit the model with the callback\n",
    "# history = model.fit_generator(train_generator, \n",
    "#                               validation_data=test_generator, \n",
    "#                               epochs=10, \n",
    "#                               verbose=2,\n",
    "#                               steps_per_epoch=1000, \n",
    "#                               validation_steps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model_weights/siamese_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_model_arc = embedding_model()\n",
    "complete_model = complete_model(emd_model_arc)\n",
    "complete_model.load_weights('model_weights/siamese_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_model = embedding_model()\n",
    "\n",
    "emd_model = complete_model.get_layer('sequential_1')\n",
    "\n",
    "# # # Get the weights of the sequential part\n",
    "# # sequential_weights = sequential_model.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seiz_train, X_seiz_test, X_bckg_train, X_bckg_test=reset_image_arr(test=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seiz_image_sample=get_image(1,test=2)\n",
    "bckg_image_sample=get_image(0,test=2)\n",
    "plt.imshow(seiz_image_sample)\n",
    "plt.show()\n",
    "plt.imshow(bckg_image_sample)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seiz_image_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seiz_image_sample_reshaped = seiz_image_sample.reshape(1, 20, 125, 1)\n",
    "bckg_image_sample_reshaped = bckg_image_sample.reshape(1, 20, 125, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seiz_image_sample_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seiz_image_sample_reshaped[0])\n",
    "plt.show()\n",
    "plt.imshow(bckg_image_sample_reshaped[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seiz_emd_sample=emd_model.predict(seiz_image_sample_reshaped)\n",
    "bckg_emd_sample=emd_model.predict(bckg_image_sample_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seiz_emd_sample,bckg_emd_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_dis=K.sum(K.square(seiz_emd_sample-bckg_emd_sample),axis=1)\n",
    "print(neg_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seiz_image_sample2=get_image(1,2)\n",
    "seiz_image_sample_reshaped2 = seiz_image_sample2.reshape(1, 20, 125, 1)\n",
    "seiz_emd_sample2=emd_model.predict(seiz_image_sample_reshaped2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dis=K.sum(K.square(seiz_emd_sample-seiz_emd_sample2),axis=1)\n",
    "print(pos_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi=[]\n",
    "si=[]\n",
    "\n",
    "for i in range(10):\n",
    "    bi.append(get_image(0,2).reshape(1, 20, 125, 1))\n",
    "    si.append(get_image(1,2).reshape(1, 20, 125, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi=np.array(bi)\n",
    "si=np.array(si)\n",
    "bi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se=[]\n",
    "be=[]\n",
    "\n",
    "for i in bi:\n",
    "    be.append(emd_model.predict(i))\n",
    "\n",
    "for i in si:\n",
    "    se.append(emd_model.predict(i))\n",
    "\n",
    "be=np.array(be)\n",
    "se=np.array(se)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.shape, be.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        bb=K.sum(K.square(be[i]-be[j]),axis=1)\n",
    "        bb=bb.numpy()[0]\n",
    "        x.append(0)\n",
    "        y.append(bb)\n",
    "\n",
    "        ss=K.sum(K.square(se[i]-se[j]),axis=1)\n",
    "        ss=ss.numpy()[0]\n",
    "        x.append(2)\n",
    "        y.append(ss)\n",
    "\n",
    "        sb=K.sum(K.square(se[i]-be[j]),axis=1)\n",
    "        sb=sb.numpy()[0]\n",
    "        x.append(1)\n",
    "        y.append(sb)\n",
    "\n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Scatter Plot Example')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classification_model(embedding_model):\n",
    "    \"\"\"\n",
    "    Create a classification model on top of the embedding model.\n",
    "    \n",
    "    Args:\n",
    "    embedding_model: Pretrained embedding model\n",
    "    \n",
    "    Returns:\n",
    "    classification_model: Model for classification on top of the embedding model\n",
    "    \"\"\"\n",
    "    # Freeze the layers of the embedding model\n",
    "    for layer in embedding_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_x, input_y, 1), name='input_layer'))  # Input layer\n",
    "    model.add(embedding_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  # 2 classes for binary classification\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Freeze pretrained model weights\n",
    "\n",
    "\n",
    "# Assuming you have an embedding_model created using your function\n",
    "\n",
    "# Create the classification model\n",
    "classifier_model = classification_model(emd_model)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer='adam',\n",
    "                          loss='sparse_categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (None, 64)                7899840   \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7904130 (30.15 MB)\n",
      "Trainable params: 4290 (16.76 KB)\n",
      "Non-trainable params: 7899840 (30.14 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_cls=generate_classification_data()\n",
    "val_generator_cls=generate_classification_data(test=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Calling reset_image at  1711826408.294237\n",
      "   --reset image started at 1711826408.294288 0 0 0 0 0\n",
      "   --reset image successfully at 1711826412.567054 0 16116 4000 16851 4028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.1196454 , 1.5703079 , 1.4554425 , ..., 0.8375998 ,\n",
       "         1.4418241 , 1.2365816 ],\n",
       "        [1.173624  , 1.2542723 , 1.1483768 , ..., 0.8491255 ,\n",
       "         0.7487686 , 1.2560912 ],\n",
       "        [1.2150924 , 1.5902333 , 1.1225473 , ..., 0.66045254,\n",
       "         1.7409877 , 1.305746  ],\n",
       "        ...,\n",
       "        [1.560252  , 0.8525763 , 1.5534775 , ..., 1.3667549 ,\n",
       "         1.1080226 , 1.5394126 ],\n",
       "        [0.3524154 , 1.541664  , 1.5150613 , ..., 1.4539295 ,\n",
       "         1.2399273 , 1.4257284 ],\n",
       "        [1.0607064 , 1.8225268 , 2.2783093 , ..., 1.7351741 ,\n",
       "         1.2098974 , 1.6203785 ]],\n",
       "\n",
       "       [[1.0914099 , 1.9225518 , 1.0889789 , ..., 1.2591628 ,\n",
       "         1.1811279 , 1.320803  ],\n",
       "        [0.641254  , 2.0200484 , 2.257233  , ..., 1.673207  ,\n",
       "         0.40913746, 0.68160355],\n",
       "        [1.1160172 , 1.0930287 , 0.6132384 , ..., 1.6005739 ,\n",
       "         1.4911256 , 0.9991855 ],\n",
       "        ...,\n",
       "        [2.643669  , 2.7811153 , 2.7216566 , ..., 2.5075114 ,\n",
       "         2.433426  , 2.2134635 ],\n",
       "        [1.8263375 , 2.172253  , 1.9608337 , ..., 1.5897859 ,\n",
       "         1.7426867 , 1.1583105 ],\n",
       "        [1.1518549 , 1.2878175 , 0.3311706 , ..., 1.7120073 ,\n",
       "         0.36702177, 0.7947184 ]],\n",
       "\n",
       "       [[1.3077507 , 2.3445492 , 2.710983  , ..., 0.7839109 ,\n",
       "         1.5619975 , 1.9001585 ],\n",
       "        [1.9271389 , 1.8769476 , 2.1267934 , ..., 1.276937  ,\n",
       "         1.1374108 , 2.0076258 ],\n",
       "        [1.2093751 , 1.3297318 , 2.5448847 , ..., 1.157075  ,\n",
       "         0.803828  , 2.1241424 ],\n",
       "        ...,\n",
       "        [2.0782666 , 1.268571  , 2.3571177 , ..., 1.3570945 ,\n",
       "         0.571755  , 1.8518759 ],\n",
       "        [1.8190364 , 1.5933424 , 1.9374772 , ..., 1.3798472 ,\n",
       "         0.89532274, 2.11683   ],\n",
       "        [1.5432047 , 1.3568717 , 2.1374488 , ..., 0.9757039 ,\n",
       "         0.97849375, 2.0223074 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.1923827 , 1.5269744 , 0.8995236 , ..., 1.3362868 ,\n",
       "         1.5739597 , 0.95512956],\n",
       "        [1.3427135 , 1.6674522 , 1.6518676 , ..., 1.8298485 ,\n",
       "         1.2786715 , 1.7830439 ],\n",
       "        [1.3866624 , 1.7426422 , 0.84627813, ..., 1.8455008 ,\n",
       "         1.4065074 , 1.7435187 ],\n",
       "        ...,\n",
       "        [1.4874122 , 1.4237463 , 1.276942  , ..., 1.6236495 ,\n",
       "         1.5283233 , 0.781341  ],\n",
       "        [1.8151702 , 1.1168414 , 1.2627015 , ..., 1.9726094 ,\n",
       "         1.0208564 , 1.470381  ],\n",
       "        [1.8330526 , 1.5587641 , 1.4483382 , ..., 1.8735952 ,\n",
       "         1.3010234 , 1.5311446 ]],\n",
       "\n",
       "       [[1.4840516 , 1.3212607 , 1.7219623 , ..., 2.334204  ,\n",
       "         1.0542859 , 1.0342488 ],\n",
       "        [0.5014925 , 0.57556397, 1.5033886 , ..., 1.9610274 ,\n",
       "         0.84162706, 0.8768474 ],\n",
       "        [0.8487875 , 0.6826557 , 1.6271231 , ..., 1.7338382 ,\n",
       "         0.50731623, 0.75295866],\n",
       "        ...,\n",
       "        [2.2670078 , 1.5959829 , 2.0480103 , ..., 2.4210732 ,\n",
       "         2.2793334 , 2.7078097 ],\n",
       "        [2.5903218 , 2.2505596 , 1.6445132 , ..., 2.1716835 ,\n",
       "         1.3398349 , 1.9999416 ],\n",
       "        [1.8662255 , 1.5193071 , 0.97929686, ..., 2.3052256 ,\n",
       "         1.4443127 , 0.5440081 ]],\n",
       "\n",
       "       [[0.6393343 , 1.4073162 , 0.6181626 , ..., 1.9038851 ,\n",
       "         1.4975168 , 0.7604726 ],\n",
       "        [1.047509  , 1.5891495 , 1.21499   , ..., 1.6185584 ,\n",
       "         0.82530737, 1.0524889 ],\n",
       "        [0.71347797, 1.6680332 , 0.6577368 , ..., 1.0678445 ,\n",
       "         1.7407913 , 1.5246619 ],\n",
       "        ...,\n",
       "        [0.71579635, 1.3888468 , 0.97202015, ..., 1.3992913 ,\n",
       "         1.2811359 , 1.2028117 ],\n",
       "        [0.8290679 , 1.5695423 , 2.0042658 , ..., 1.9446477 ,\n",
       "         1.3273785 , 1.1337924 ],\n",
       "        [1.3383596 , 1.6027018 , 1.5342898 , ..., 1.2827528 ,\n",
       "         1.6632448 , 1.420496  ]]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(train_generator_cls)\n",
    "batch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/5sdbkwy556z7qfq1lmd8s15c0000gn/T/ipykernel_15052/3831115453.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = classifier_model.fit_generator(train_generator_cls,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "  87/1000 [=>............................] - ETA: 22s - loss: 0.8660 - accuracy: 0.6530--Calling reset_image at  1711826435.474688\n",
      "   --reset image started at 1711826435.477947 0 0 0 0 0\n",
      "  98/1000 [=>............................] - ETA: 22s - loss: 0.8494 - accuracy: 0.6553   --reset image successfully at 1711826439.9340842 0 16162 4000 16243 4342\n",
      " 182/1000 [====>.........................] - ETA: 41s - loss: 0.7711 - accuracy: 0.6538--Calling reset_image at  1711826442.347718\n",
      "   --reset image started at 1711826442.349988 0 0 0 0 0\n",
      " 197/1000 [====>.........................] - ETA: 38s - loss: 0.7635 - accuracy: 0.6548   --reset image successfully at 1711826446.217503 0 16510 4000 16087 4025\n",
      " 266/1000 [======>.......................] - ETA: 43s - loss: 0.7042 - accuracy: 0.6779--Calling reset_image at  1711826448.939577\n",
      "   --reset image started at 1711826448.940127 0 0 0 0 0\n",
      " 299/1000 [=======>......................] - ETA: 38s - loss: 0.6850 - accuracy: 0.6854   --reset image successfully at 1711826453.774126 0 16052 4000 16045 4017\n",
      " 333/1000 [========>.....................] - ETA: 46s - loss: 0.6740 - accuracy: 0.6860--Calling reset_image at  1711826456.512813\n",
      "   --reset image started at 1711826456.513503 0 0 0 0 0\n",
      " 399/1000 [==========>...................] - ETA: 36s - loss: 0.6540 - accuracy: 0.6916   --reset image successfully at 1711826460.3688672 0 16406 4000 16048 4018\n",
      " 434/1000 [============>.................] - ETA: 38s - loss: 0.6494 - accuracy: 0.6912--Calling reset_image at  1711826462.389907\n",
      "   --reset image started at 1711826462.3941681 0 0 0 0 0\n",
      " 496/1000 [=============>................] - ETA: 31s - loss: 0.6419 - accuracy: 0.6915   --reset image successfully at 1711826466.7052329 0 16421 4000 16016 4063\n",
      " 532/1000 [==============>...............] - ETA: 31s - loss: 0.6290 - accuracy: 0.6977--Calling reset_image at  1711826469.1795452\n",
      "   --reset image started at 1711826469.182139 0 0 0 0 0\n",
      " 596/1000 [================>.............] - ETA: 25s - loss: 0.6062 - accuracy: 0.7108   --reset image successfully at 1711826474.2816482 0 16488 4000 16118 4010\n",
      " 645/1000 [==================>...........] - ETA: 24s - loss: 0.6079 - accuracy: 0.7101--Calling reset_image at  1711826477.423529\n",
      "   --reset image started at 1711826477.424552 0 0 0 0 0\n",
      " 698/1000 [===================>..........] - ETA: 19s - loss: 0.6101 - accuracy: 0.7089   --reset image successfully at 1711826482.3981051 0 16506 4000 16215 4187\n",
      " 736/1000 [=====================>........] - ETA: 18s - loss: 0.6057 - accuracy: 0.7112--Calling reset_image at  1711826484.784897\n",
      "   --reset image started at 1711826484.789402 0 0 0 0 0\n",
      " 798/1000 [======================>.......] - ETA: 13s - loss: 0.5990 - accuracy: 0.7129   --reset image successfully at 1711826491.191725 0 16569 4000 16051 4044\n",
      " 830/1000 [=======================>......] - ETA: 12s - loss: 0.5960 - accuracy: 0.7140--Calling reset_image at  1711826493.803614\n",
      "   --reset image started at 1711826493.805047 0 0 0 0 0\n",
      " 896/1000 [=========================>....] - ETA: 7s - loss: 0.5902 - accuracy: 0.7162   --reset image successfully at 1711826499.626684 0 16135 4000 16010 4107\n",
      " 928/1000 [==========================>...] - ETA: 5s - loss: 0.5908 - accuracy: 0.7148--Calling reset_image at  1711826501.8768902\n",
      "   --reset image started at 1711826501.8780081 0 0 0 0 0\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.5914 - accuracy: 0.7114   --reset image successfully at 1711826506.088914 0 16198 4000 16032 4007\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.5912 - accuracy: 0.7114--Calling reset_image at  1711826507.6626308\n",
      "   --reset image started at 1711826507.662694 1 0 0 0 0\n",
      "   --reset image successfully at 1711826511.763647 1 16631 4000 16425 4008\n",
      "\n",
      "Epoch 1: saving model to model_weights/siamese_classification_model_3.h5\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.5912 - accuracy: 0.7114 - val_loss: 0.6624 - val_accuracy: 0.6812\n",
      "Epoch 2/4\n",
      "   1/1000 [..............................] - ETA: 52s - loss: 0.4709 - accuracy: 0.7812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  68/1000 [=>............................] - ETA: 39s - loss: 0.5175 - accuracy: 0.7537--Calling reset_image at  1711826516.5932531\n",
      "   --reset image started at 1711826516.595 0 0 0 0 0\n",
      "  99/1000 [=>............................] - ETA: 30s - loss: 0.5123 - accuracy: 0.7541   --reset image successfully at 1711826522.219085 0 16056 4000 16015 4013\n",
      " 135/1000 [===>..........................] - ETA: 1:07 - loss: 0.5091 - accuracy: 0.7530--Calling reset_image at  1711826524.2532868\n",
      "   --reset image started at 1711826524.2543821 0 0 0 0 0\n",
      " 198/1000 [====>.........................] - ETA: 48s - loss: 0.5060 - accuracy: 0.7544   --reset image successfully at 1711826529.664901 0 16485 4000 16035 4045\n",
      " 238/1000 [======>.......................] - ETA: 1:00 - loss: 0.5197 - accuracy: 0.7505--Calling reset_image at  1711826532.7547\n",
      "   --reset image started at 1711826532.755338 0 0 0 0 0\n",
      " 296/1000 [=======>......................] - ETA: 48s - loss: 0.5315 - accuracy: 0.7483   --reset image successfully at 1711826537.2259881 0 16101 4000 16006 4015\n",
      " 331/1000 [========>.....................] - ETA: 52s - loss: 0.5333 - accuracy: 0.7481--Calling reset_image at  1711826539.792115\n",
      "   --reset image started at 1711826539.7935371 0 0 0 0 0\n",
      " 397/1000 [==========>...................] - ETA: 41s - loss: 0.5343 - accuracy: 0.7510   --reset image successfully at 1711826544.0187352 0 16961 4000 16025 4040\n",
      " 429/1000 [===========>..................] - ETA: 43s - loss: 0.5315 - accuracy: 0.7512--Calling reset_image at  1711826546.577728\n",
      "   --reset image started at 1711826546.578898 0 0 0 0 0\n",
      " 496/1000 [=============>................] - ETA: 34s - loss: 0.5232 - accuracy: 0.7536   --reset image successfully at 1711826552.483742 0 16294 4000 16028 4052\n",
      " 534/1000 [===============>..............] - ETA: 36s - loss: 0.5310 - accuracy: 0.7494--Calling reset_image at  1711826555.301099\n",
      "   --reset image started at 1711826555.3032289 0 0 0 0 0\n",
      " 599/1000 [================>.............] - ETA: 28s - loss: 0.5409 - accuracy: 0.7414   --reset image successfully at 1711826560.83343 0 16406 4000 16014 4045\n",
      " 634/1000 [==================>...........] - ETA: 28s - loss: 0.5363 - accuracy: 0.7445--Calling reset_image at  1711826563.236474\n",
      "   --reset image started at 1711826563.236515 0 0 0 0 0\n",
      " 697/1000 [===================>..........] - ETA: 22s - loss: 0.5259 - accuracy: 0.7517   --reset image successfully at 1711826567.329196 0 16133 4000 16006 4217\n",
      " 739/1000 [=====================>........] - ETA: 19s - loss: 0.5281 - accuracy: 0.7502--Calling reset_image at  1711826569.784132\n",
      "   --reset image started at 1711826569.784702 0 0 0 0 0\n",
      " 799/1000 [======================>.......] - ETA: 14s - loss: 0.5286 - accuracy: 0.7490   --reset image successfully at 1711826574.940109 0 16501 4000 16329 4124\n",
      " 831/1000 [=======================>......] - ETA: 12s - loss: 0.5258 - accuracy: 0.7503--Calling reset_image at  1711826577.458977\n",
      "   --reset image started at 1711826577.461424 0 0 0 0 0\n",
      " 896/1000 [=========================>....] - ETA: 7s - loss: 0.5199 - accuracy: 0.7532   --reset image successfully at 1711826583.678625 0 16272 4000 16030 4005\n",
      " 935/1000 [===========================>..] - ETA: 5s - loss: 0.5191 - accuracy: 0.7539--Calling reset_image at  1711826587.3393338\n",
      "   --reset image started at 1711826587.340107 0 0 0 0 0\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.7543   --reset image successfully at 1711826593.270408 0 16478 4000 16043 4055\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.5190 - accuracy: 0.7544\n",
      "Epoch 2: saving model to model_weights/siamese_classification_model_3.h5\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.5190 - accuracy: 0.7544 - val_loss: 0.5737 - val_accuracy: 0.7177\n",
      "Epoch 3/4\n",
      "   8/1000 [..............................] - ETA: 15s - loss: 0.4625 - accuracy: 0.7969--Calling reset_image at  1711826595.764211\n",
      "   --reset image started at 1711826595.766648 0 0 0 0 0\n",
      "  99/1000 [=>............................] - ETA: 17s - loss: 0.4807 - accuracy: 0.7784   --reset image successfully at 1711826601.821592 0 16054 4000 16015 4063\n",
      " 135/1000 [===>..........................] - ETA: 54s - loss: 0.5117 - accuracy: 0.7588--Calling reset_image at  1711826604.014574\n",
      "   --reset image started at 1711826604.01709 0 0 0 0 0\n",
      " 198/1000 [====>.........................] - ETA: 40s - loss: 0.5312 - accuracy: 0.7416   --reset image successfully at 1711826608.418017 0 16506 4000 16192 4076\n",
      " 258/1000 [======>.......................] - ETA: 45s - loss: 0.5310 - accuracy: 0.7389--Calling reset_image at  1711826611.2715971\n",
      "   --reset image started at 1711826611.273771 0 0 0 0 0\n",
      " 299/1000 [=======>......................] - ETA: 39s - loss: 0.5307 - accuracy: 0.7366   --reset image successfully at 1711826615.652127 0 16120 4000 16000 4070\n",
      " 335/1000 [=========>....................] - ETA: 44s - loss: 0.5391 - accuracy: 0.7333--Calling reset_image at  1711826617.854487\n",
      "   --reset image started at 1711826617.856213 0 0 0 0 0\n",
      " 395/1000 [==========>...................] - ETA: 36s - loss: 0.5495 - accuracy: 0.7253   --reset image successfully at 1711826623.134536 0 16855 4000 16024 4030\n",
      " 430/1000 [===========>..................] - ETA: 40s - loss: 0.5383 - accuracy: 0.7326--Calling reset_image at  1711826626.446576\n",
      "   --reset image started at 1711826626.4471 0 0 0 0 0\n",
      " 496/1000 [=============>................] - ETA: 33s - loss: 0.5192 - accuracy: 0.7448   --reset image successfully at 1711826630.8452249 0 16432 4000 16000 4017\n",
      " 536/1000 [===============>..............] - ETA: 32s - loss: 0.5186 - accuracy: 0.7443--Calling reset_image at  1711826633.345075\n",
      "   --reset image started at 1711826633.3477929 0 0 0 0 0\n",
      " 597/1000 [================>.............] - ETA: 26s - loss: 0.5145 - accuracy: 0.7463   --reset image successfully at 1711826638.5517051 0 16335 4000 16003 4048\n",
      " 627/1000 [=================>............] - ETA: 26s - loss: 0.5174 - accuracy: 0.7439--Calling reset_image at  1711826640.6528058\n",
      "   --reset image started at 1711826640.653171 0 0 0 0 0\n",
      " 698/1000 [===================>..........] - ETA: 20s - loss: 0.5215 - accuracy: 0.7423   --reset image successfully at 1711826644.924459 0 16055 4000 16000 4456\n",
      " 730/1000 [====================>.........] - ETA: 19s - loss: 0.5203 - accuracy: 0.7431--Calling reset_image at  1711826647.460018\n",
      "   --reset image started at 1711826647.461922 0 0 0 0 0\n",
      " 799/1000 [======================>.......] - ETA: 13s - loss: 0.5209 - accuracy: 0.7423   --reset image successfully at 1711826651.235949 0 16119 4000 16035 4010\n",
      " 829/1000 [=======================>......] - ETA: 11s - loss: 0.5204 - accuracy: 0.7428--Calling reset_image at  1711826653.048235\n",
      "   --reset image started at 1711826653.050262 0 0 0 0 0\n",
      " 895/1000 [=========================>....] - ETA: 6s - loss: 0.5203 - accuracy: 0.7442   --reset image successfully at 1711826657.075645 0 16106 4000 16863 4070\n",
      " 940/1000 [===========================>..] - ETA: 4s - loss: 0.5181 - accuracy: 0.7451--Calling reset_image at  1711826659.3984902\n",
      "   --reset image started at 1711826659.3993669 0 0 0 0 0\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.5160 - accuracy: 0.7467   --reset image successfully at 1711826663.855478 0 16349 4000 16124 4098\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.7469\n",
      "Epoch 3: saving model to model_weights/siamese_classification_model_3.h5\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.5156 - accuracy: 0.7469 - val_loss: 0.6246 - val_accuracy: 0.6719\n",
      "Epoch 4/4\n",
      "  36/1000 [>.............................] - ETA: 22s - loss: 0.5037 - accuracy: 0.7639--Calling reset_image at  1711826666.489843\n",
      "   --reset image started at 1711826666.493153 0 0 0 0 0\n",
      "  98/1000 [=>............................] - ETA: 17s - loss: 0.4791 - accuracy: 0.7758   --reset image successfully at 1711826670.6182442 0 16108 4000 16054 4010\n",
      " 134/1000 [===>..........................] - ETA: 43s - loss: 0.4507 - accuracy: 0.7906--Calling reset_image at  1711826672.284909\n",
      "   --reset image started at 1711826672.2864199 0 0 0 0 0\n",
      " 196/1000 [====>.........................] - ETA: 33s - loss: 0.4474 - accuracy: 0.7956   --reset image successfully at 1711826677.867628 0 16083 4000 16028 4021\n",
      " 235/1000 [======>.......................] - ETA: 49s - loss: 0.4766 - accuracy: 0.7726--Calling reset_image at  1711826680.816781\n",
      "   --reset image started at 1711826680.819793 0 0 0 0 0\n",
      " 298/1000 [=======>......................] - ETA: 38s - loss: 0.5106 - accuracy: 0.7435   --reset image successfully at 1711826685.345949 0 16043 4000 16261 4068\n",
      " 333/1000 [========>.....................] - ETA: 43s - loss: 0.5131 - accuracy: 0.7423--Calling reset_image at 1711826687.3671758\n",
      "   --reset image started at 1711826687.368734 0 0 0 0 0\n",
      " 397/1000 [==========>...................] - ETA: 35s - loss: 0.5158 - accuracy: 0.7405   --reset image successfully at 1711826691.611732 0 16132 4000 16074 4080\n",
      " 435/1000 [============>.................] - ETA: 36s - loss: 0.5193 - accuracy: 0.7375--Calling reset_image at  1711826693.838295\n",
      "   --reset image started at 1711826693.8388832 0 0 0 0 0\n",
      " 496/1000 [=============>................] - ETA: 30s - loss: 0.5181 - accuracy: 0.7377   --reset image successfully at 1711826698.2298398 0 16500 4000 16176 4154\n",
      " 536/1000 [===============>..............] - ETA: 30s - loss: 0.5198 - accuracy: 0.7370--Calling reset_image at  1711826700.722919\n",
      "   --reset image started at 1711826700.726485 0 0 0 0 0\n",
      " 596/1000 [================>.............] - ETA: 24s - loss: 0.5206 - accuracy: 0.7368   --reset image successfully at 1711826705.861184 0 16251 4000 16015 4017\n",
      " 627/1000 [=================>............] - ETA: 25s - loss: 0.5179 - accuracy: 0.7386--Calling reset_image at  1711826707.962922\n",
      "   --reset image started at 1711826707.9646661 0 0 0 0 0\n",
      " 696/1000 [===================>..........] - ETA: 19s - loss: 0.5093 - accuracy: 0.7450   --reset image successfully at 1711826713.606681 0 16894 4000 16055 4024\n",
      " 725/1000 [====================>.........] - ETA: 19s - loss: 0.5085 - accuracy: 0.7451--Calling reset_image at  1711826716.489252\n",
      "   --reset image started at 1711826716.489768 0 0 0 0 0\n",
      " 797/1000 [======================>.......] - ETA: 13s - loss: 0.5060 - accuracy: 0.7456   --reset image successfully at 1711826720.6977 0 16295 4000 16396 4052\n",
      " 835/1000 [========================>.....] - ETA: 11s - loss: 0.5010 - accuracy: 0.7488--Calling reset_image at  1711826723.183856\n",
      "   --reset image started at 1711826723.185722 0 0 0 0 0\n",
      " 896/1000 [=========================>....] - ETA: 6s - loss: 0.4937 - accuracy: 0.7543   --reset image successfully at 1711826728.318043 0 16263 4000 16004 4323\n",
      " 935/1000 [===========================>..] - ETA: 4s - loss: 0.4935 - accuracy: 0.7552--Calling reset_image at  1711826730.3617961\n",
      "   --reset image started at 1711826730.362436 0 0 0 0 0\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.4931 - accuracy: 0.7565   --reset image successfully at 1711826734.495426 0 16188 4000 16006 4031\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.7565--Calling reset_image at  1711826736.184386\n",
      "   --reset image started at 1711826736.1892228 1 0 0 0 0\n",
      "   --reset image successfully at 1711826739.961487 1 16396 4000 16072 4048\n",
      "\n",
      "Epoch 4: saving model to model_weights/siamese_classification_model_3.h5\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.4932 - accuracy: 0.7565 - val_loss: 0.5234 - val_accuracy: 0.7531\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define a callback to save the model weights after each epoch\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_weights/siamese_classification_model_3.h5', \n",
    "                                      save_weights_only=False,\n",
    "                                      verbose=1)\n",
    "\n",
    "# Fit the model with the callback\n",
    "history = classifier_model.fit_generator(train_generator_cls, \n",
    "                              validation_data=val_generator_cls, \n",
    "                              epochs=4, \n",
    "                              verbose=1,\n",
    "                              steps_per_epoch=1000, \n",
    "                              validation_steps=30,\n",
    "                              callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_model_arc = embedding_model()\n",
    "classifier_model_final = classification_model(emd_model_arc)\n",
    "classifier_model_final.load_weights('model_weights/siamese_classification_model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_image=get_image(0,2).reshape(1, 20, 125, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_image=get_image(1,2).reshape(1, 20, 125, 1)\n",
    "classifier_model_final.predict(rnd_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Calling reset_image at  1711826819.635697\n",
      "   --reset image started at 1711826819.6358101 2 0 0 0 0\n",
      "   --reset image successfully at 1711826821.8939729 2 0 20127 0 20043\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "--Calling reset_image at  1711826834.528335\n",
      "   --reset image started at 1711826834.528388 2 0 0 0 0\n",
      "   --reset image successfully at 1711826838.599274 2 0 20150 0 20022\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "--Calling reset_image at  1711826844.192186\n",
      "   --reset image started at 1711826844.192238 2 0 0 0 0\n",
      "   --reset image successfully at 1711826848.093178 2 0 20161 0 20381\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "--Calling reset_image at  1711826856.405177\n",
      "   --reset image started at 1711826856.4052532 2 0 0 0 0\n",
      "   --reset image successfully at 1711826861.559017 2 0 20218 0 20156\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.79      4992\n",
      "           1       0.87      0.60      0.71      4992\n",
      "\n",
      "    accuracy                           0.76      9984\n",
      "   macro avg       0.78      0.76      0.75      9984\n",
      "weighted avg       0.78      0.76      0.75      9984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have already defined and loaded your model\n",
    "# model = ...\n",
    "\n",
    "# Generate data\n",
    "num_samples=10000\n",
    "\n",
    "data_generator = generate_classification_data(test=2)\n",
    "\n",
    "# Initialize lists to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate over the generated data and obtain predictions\n",
    "for i in range(num_samples // batch_size):  # Adjust num_samples as per your need\n",
    "    X, y_true = next(data_generator)\n",
    "    y_pred = classifier_model_final.predict(X)  # Assuming model.predict returns probabilities\n",
    "\n",
    "    true_labels.extend(y_true)\n",
    "    predicted_labels.extend(np.argmax(y_pred, axis=1))  # Convert probabilities to class labels\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and print classification report\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
